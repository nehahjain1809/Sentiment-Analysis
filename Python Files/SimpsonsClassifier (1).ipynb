{"cells":[{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport os\nimport csv\nimport seaborn as sns\nimport json\nfrom decimal import Decimal\nimport nltk\n#nltk.download()\nfrom nltk.corpus import stopwords\nimport string\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import *\nfrom afinn import Afinn\n# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n# analyser = SentimentIntensityAnalyzer()\nafinn=Afinn()\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import classification_report"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def text_to_sentiment_score(text):\n   return afinn.score(text)\n\ndef sentiment_score_to_category(score):\n    if(score>0):\n        return 'positive'\n    if(score<0):\n        return 'negative'\n    if(score==0):\n        return 'neutral'\n      \n\ndef clean_text(normalized_text):\n    nopunc = [char for char in normalized_text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n      \nmaxUdf=udf(text_to_sentiment_score, FloatType())\nmaxUdf1=udf(sentiment_score_to_category, StringType())\nmaxUdf2=udf(clean_text, StringType())\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["inputPath = \"/FileStore/tables/\"\n\ndf_episode = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/Episode24.csv')"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(df_episode)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/FileStore/tables/Episode24.csv\")\n\ndata.cache() # Cache data for faster reuse\ndata = data.dropna() # drop rows with missing values\n\n# Register table so it is accessible via SQL Context\n# For Apache Spark = 2.0\ndata.createOrReplaceTempView(\"data_tbl\")\n#display(data)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["data = data.withColumn(\"sentiment_score\", maxUdf('normalized_text'))\ndata = data.withColumn(\"sentiment\", maxUdf1('sentiment_score'))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["data.createOrReplaceTempView(\"data_tbl\")\ndisplay(data)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["data=data.select(\"episode_id\",\"normalized_text\",\"sentiment\").rdd.toDF()\n# display(data)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = [\"normalized_text\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["cols = data.columns\nprint(cols)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Transform all features into a vector using VectorAssembler\nnumericCols = [\"episode_id\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(data)\ndata = pipelineModel.transform(data)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ndata = data.select(selectedcols)\ndisplay(data)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["(trainingData, testData) = data.randomSplit([0.7, 0.3], seed = 100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Make predictions on test data using the transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\", \"normalized_text\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["evaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["print lr.explainParams()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# this will likely take a fair amount of time because of the amount of models that we're creating and testing"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["predictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["print 'Model Intercept: ', cvModel.bestModel.interceptVector"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["print \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"normalized_text\", \"sentiment\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["Random Forest"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = rfModel.transform(testData)\npredictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"normalized_text\", \"sentiment\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["Evaluate using Binary classification"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"normalized_text\", \"sentiment\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["bestModel = cvModel.bestModel"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["# Generate predictions for entire dataset\nfinalPredictions = bestModel.transform(data)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["# Evaluate best model\nevaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["finalPredictions.createOrReplaceTempView(\"finalPredictions\")"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["%sql\nselect * from finalPredictions"],"metadata":{},"outputs":[],"execution_count":46}],"metadata":{"name":"SimpsonsClassifier","notebookId":218981913978021},"nbformat":4,"nbformat_minor":0}
